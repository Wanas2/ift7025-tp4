{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils.metrics as metrics\n",
    "import utils.maths as maths\n",
    "import utils.encoding as encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet: #nom de la class à changer\n",
    "\n",
    "    def __init__(self, sizes, init_weights_method=\"Xavier\"):\n",
    "        \"\"\"\n",
    "        C'est un Initializer. \n",
    "        Vous pouvez passer d'autre paramètres au besoin,\n",
    "        c'est à vous d'utiliser vos propres notations\n",
    "\n",
    "        sizes : Liste de nombre de noeuds dans la couche d'entrée, \n",
    "                dans la couche cachée et dans la couche de sortie.\n",
    "        \"\"\"\n",
    "\n",
    "        self.n_inputs = sizes[0]\n",
    "        self.n_hidden = sizes[1]\n",
    "        self.n_outputs = sizes[2]\n",
    "        \n",
    "        self.cache = {}\n",
    "\n",
    "        self.weights_bias = {\n",
    "            \"Weights Hidden\" : self._init_weights(self.n_inputs, self.n_hidden, init_weights_method),\n",
    "            \"Bias Hidden\" : self._init_bias(self.n_inputs, self.n_hidden, init_weights_method),\n",
    "            \"Weights Output\" : self._init_weights(self.n_hidden, self.n_outputs, init_weights_method),\n",
    "            \"Bias Output\" : self._init_bias(self.n_hidden, self.n_outputs, init_weights_method)\n",
    "        }\n",
    "        \n",
    "        \n",
    "    def train(self, train, train_labels, learning_rate, n_iterations, threshold):\n",
    "        self.iter = n_iterations\n",
    "        train_labels = encoding.transformLabel(train_labels)\n",
    "        \n",
    "        for i in range(self.iter):\n",
    "            # Batch\n",
    "            x = train\n",
    "            y = train_labels\n",
    "            \n",
    "            # Forward propagation\n",
    "            output = self._forward_propagation(x)\n",
    "            # Backpropagation\n",
    "            _ = self._backward_propagation(y, output)\n",
    "            # Weights and bias update\n",
    "            self.weights_bias_update(learning_rate)\n",
    "\n",
    "            # error = sum((self.cache[\"A Output\"]-y)**2)/2\n",
    "            # if error < threshold:\n",
    "            #     break\n",
    "\n",
    "    def predict(self, x):\n",
    "        out = self._forward_propagation(x).tolist()\n",
    "        return str(out.index(max(out)))\n",
    "        \n",
    "    def evaluate(self, X, y):\n",
    "        labels = np.unique(y)\n",
    "\n",
    "        predictions = list()\n",
    "        for x in X:\n",
    "            predictions.append(self.predict(x))\n",
    "\n",
    "        predictions = np.array(predictions)\n",
    "\n",
    "        unique_labels = set(labels)\n",
    "        unique_labels.update(y)\n",
    "        self.unique_labels = list(unique_labels)\n",
    "\n",
    "        self.n_labels = len(unique_labels)\n",
    "        \n",
    "        return self._get_metrics(predictions, y)\n",
    "\n",
    "    def _get_metrics(self, y_pred, y_true):\n",
    "        if self.n_labels == 2:\n",
    "            con_matrix = metrics.binary_confusion_matrix(y_pred, y_true, self.unique_labels[0])\n",
    "            accuracy = metrics.accuracy_metrics(con_matrix)\n",
    "            precision = metrics.precision_metrics(con_matrix)\n",
    "            recall = metrics.recall_metrics(con_matrix)\n",
    "            f1_score = metrics.f1_score_metrics(con_matrix)\n",
    "        elif self.n_labels > 2:\n",
    "            con_matrix = metrics.multilabel_confusion_matrix(y_pred, y_true, self.unique_labels)\n",
    "            \n",
    "            accuracy = [metrics.accuracy_metrics(con_matrix[i]) for i in range(self.n_labels)] \n",
    "\n",
    "            precision = [metrics.precision_metrics(con_matrix[i]) for i in range(self.n_labels)]  \n",
    "\n",
    "            recall = [metrics.recall_metrics(con_matrix[i]) for i in range(self.n_labels)]\n",
    "\n",
    "            f1_score = [metrics.f1_score_metrics(con_matrix[i]) for i in range(self.n_labels)]\n",
    "\n",
    "        return ({\n",
    "            \"con_matrix\": con_matrix,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1_score\n",
    "        })\n",
    "\n",
    "    def _init_weights(self, input_size, output_size, init_method):\n",
    "        if init_method == \"Zero\":\n",
    "            weights = np.zeros((output_size, input_size)) \n",
    "        if init_method == \"Xavier\":\n",
    "            weights = np.random.randn(output_size, input_size) * np.sqrt(2/(input_size+output_size))\n",
    "        return weights\n",
    "\n",
    "    def _init_bias(self, input_size, output_size, init_method):\n",
    "        if init_method == \"Zero\":\n",
    "            weights = np.zeros((output_size, 1))\n",
    "        if init_method == \"Xavier\":\n",
    "            weights = np.zeros((output_size, 1)) * np.sqrt(1/(input_size))\n",
    "        return weights\n",
    "\n",
    "    def _forward_propagation(self, x):\n",
    "        \"\"\"\n",
    "        Faire la propagation à partir d'un exemple x donné en entrée.\n",
    "        Exemple est de taille 1xm.\n",
    "        \"\"\"\n",
    "        self.cache[\"X\"] = x\n",
    "        self.cache[\"Z Hidden\"] = np.matmul(self.weights_bias[\"Weights Hidden\"], self.cache[\"X\"].T) + self.weights_bias[\"Bias Hidden\"]\n",
    "        self.cache[\"A Hidden\"] = maths.sigmoid(self.cache[\"Z Hidden\"])\n",
    "        self.cache[\"Z Output\"] = np.matmul(self.weights_bias[\"Weights Output\"], self.cache[\"A Hidden\"]) + self.weights_bias[\"Bias Output\"]\n",
    "        self.cache[\"A Output\"] = maths.sigmoid(self.cache[\"Z Output\"])\n",
    "        return self.cache[\"A Output\"]\n",
    "\n",
    "    def _backward_propagation(self, y, output):\n",
    "        n_labels = y.shape[0]\n",
    "        \n",
    "        dZOutput = output - y.T\n",
    "        dWOutput = (1/n_labels) * np.matmul(dZOutput, self.cache[\"A Hidden\"].T)\n",
    "        dbOutput = (1/n_labels) * np.sum(dZOutput, axis=1, keepdims=True)\n",
    "\n",
    "        dAHidden = np.matmul(self.weights_bias[\"Weights Output\"].T, dZOutput)\n",
    "        dZHidden = dAHidden * maths.sigmoid_prime(self.cache[\"Z Hidden\"])\n",
    "        dWHidden = (1/n_labels) * np.matmul(dZHidden, self.cache[\"X\"])\n",
    "        dbHidden = (1/n_labels) * np.sum(dZHidden, axis=1, keepdims=True)\n",
    "\n",
    "        self.grads = {\"Weights Hidden\": dWHidden, \"Bias Hidden\": dbHidden, \"Weights Output\": dWOutput, \"Bias Output\": dbOutput}\n",
    "        return self.grads\n",
    "    \n",
    "    def weights_bias_update(self, learning_rate):\n",
    "        for key in self.weights_bias:\n",
    "            self.weights_bias[key] = self.weights_bias[key] - learning_rate * self.grads[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_datasets.load_wine_dataset(70)\n",
    "X_train = X_train.astype(np.float64)\n",
    "X_test = X_test.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf  = NeuralNet([11, 6, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.train(X_train, y_train, 0.3, 1000, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test[0].reshape(1, X_test[0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'con_matrix': [[0, 478], [0, 332]],\n",
       " 'accuracy': 0.40987654320987654,\n",
       " 'precision': 0.40987654320987654,\n",
       " 'recall': 1.0,\n",
       " 'f1_score': 0.5814360770577933}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6)\n",
      "(6, 6)\n",
      "(2, 6)\n",
      "(2, 6)\n"
     ]
    }
   ],
   "source": [
    "print(clf.cache[\"Z Hidden\"].shape)\n",
    "print(clf.cache[\"A Hidden\"].shape)\n",
    "print(clf.cache[\"Z Output\"].shape)\n",
    "print(clf.cache[\"A Output\"].shape)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6591d35b76ab97e93406cb5781dab5e47afa94dc95163fbd3bb09bb5745da70e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
