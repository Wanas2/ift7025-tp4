{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbre de décision\n",
    "\n",
    "#### Courbe d'apprentissage\n",
    "\n",
    "<img src=\"learning_curve.png\">\n",
    "\n",
    "On constate que plus on a de données en entrainement plus on performe bien. \\\n",
    "Aussi, on observe deux grandes phases sur ce graphe:\n",
    "- Une augmentation fulgurante pour les premières tailles de notre jeu de données;\n",
    "- Et une phase où les performances n'évoluent que très peu.\n",
    "\n",
    "Cette 2ème phase nous permet donc de déduire qu'on pourrait réduire le jeu d'entrainement\n",
    "pour gagner en temps sans toute fois perdre en terme de généralisation sur le jeu de test.\n",
    "\n",
    "#### Comparaison avec le classifieur scikit-learn\n",
    "\n",
    "Nous obetenons des résultats similaires sur le jeu de données iris. \\\n",
    "Sur le de données wine, le classifieur de sklearn perfome mieux que le notre. \\\n",
    "Tandis que sur le jeu de données abalone, c'est notre classifieur qui a les meilleurs performances.\n",
    "\n",
    "Les résultats obtenus sont regroupés dans les tableaux ci-bas:\n",
    "\n",
    "##### Custom\n",
    "<table>\n",
    "    <tr>\n",
    "        <th></th>\n",
    "        <th>Accuracy</th>\n",
    "        <th>Precision</th>\n",
    "        <th>Recall</th>\n",
    "        <th>F1-score</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>iris</th>\n",
    "        <td>[100, 91.67, 91.67]</td>\n",
    "        <td>[100, 75, 100]</td>\n",
    "        <td>[100, 100, 80]</td>\n",
    "        <td>[100, 85.71, 88.89]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>wine</th>\n",
    "        <td>85.43</td>\n",
    "        <td>79.89</td>\n",
    "        <td>86.14</td>\n",
    "        <td>82.90</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>abalone</th>\n",
    "        <td>[93.54, 84.05, 90.51]</td>\n",
    "        <td>[69.80, 80.25, 62.79]</td>\n",
    "        <td>[74.29, 88.54, 66.26]</td>\n",
    "        <td>[71.97, 89.38, 64.48]</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "##### Sklearn\n",
    "<table>\n",
    "    <tr>\n",
    "        <th></th>\n",
    "        <th>Accuracy</th>\n",
    "        <th>Precision</th>\n",
    "        <th>Recall</th>\n",
    "        <th>F1-score</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>iris</th>\n",
    "        <td>[100, 91.67, 91.67]</td>\n",
    "        <td>[100, 75, 100]</td>\n",
    "        <td>[100, 100, 80]</td>\n",
    "        <td>[100, 85.71, 88.89]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>wine</th>\n",
    "        <td>88.15</td>\n",
    "        <td>87.62</td>\n",
    "        <td>88.49</td>\n",
    "        <td>87.91</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>abalone</th>\n",
    "        <td>[94.25, 83.65, 89.39]</td>\n",
    "        <td>[72.67, 90.28, 58.43]</td>\n",
    "        <td>[77.86, 87.90, 63.80]</td>\n",
    "        <td>[75.17, 89.08, 61.00]</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "#### Comparaison avec élagage\n",
    "\n",
    "Les résultats ci-bas montrent l'évaluation de notre classifieur après élagage.\n",
    "\n",
    "##### Prune\n",
    "<table>\n",
    "    <tr>\n",
    "        <th></th>\n",
    "        <th>Accuracy</th>\n",
    "        <th>Precision</th>\n",
    "        <th>Recall</th>\n",
    "        <th>F1-score</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>iris</th>\n",
    "        <td>[100, 91.67, 91.67]</td>\n",
    "        <td>[100, 75, 100]</td>\n",
    "        <td>[100, 100, 80]</td>\n",
    "        <td>[100, 85.71, 88.89]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>wine</th>\n",
    "        <td>85.43</td>\n",
    "        <td>79.89</td>\n",
    "        <td>86.14</td>\n",
    "        <td>82.90</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>abalone</th>\n",
    "        <td>[92.98, 83.25, 90.35]</td>\n",
    "        <td>[66.25, 90.05, 62.65]</td>\n",
    "        <td>[75.71, 87.59, 63.80]</td>\n",
    "        <td>[70.67, 88.89, 63.22]</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "On constate, qu'on a une dégradation des performances sur le jeu de test. \\\n",
    "Ce qui signifie qu'on a probablement mal élagué notre arbre. Mais on n'a pas eu assez de temps pour vérifier d'où vient le problème "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseaux de Neurones Artificiels\n",
    "\n",
    "### Initialisation des poids du réseau de neurones\n",
    "\n",
    "Nous avons choisi d’utiliser la technique d’initialisation Normal de Xavier. Elle consiste à initialiser les poids de façon aléatoire suivant une loi Normal avec une moyenne de 0 et un écart-type de $$\\sigma=\\sqrt{\\frac{2}{Nombre\\ d'input\\ +\\ Nombre\\ d'output}}.$$\n",
    "\n",
    "Toutes les figures suivantes représentent les courbes d’apprentissage des réseaux neurones en utilisant l’initialisation Normal de Xavier et l’initialisation des poids à zéros pour les trois jeux de données.\n",
    "\n",
    "<img src=\"Images\\XavierIris.png\">\n",
    "\n",
    "<img src=\"Images\\ZeroIris.png\">\n",
    "\n",
    "En comparant les figures 1 et 2, on remarque que l’apprentissage avec l’initialisation de Xavier est beaucoup plus constant qu’avec l’initialisation à zéro. Cependant, l’initialisation à zéro commence avec une meilleure prédiction. Le modèle semble ensuite rester constant sans s’améliorer, mais il y a beaucoup d’inconstance lorsque le jeu de donnée devient plus grand. Pour ce qui est de l’initialisation de Xavier, il semble toujours y avoir une certaine amélioration du modèle même si elle est de moins en moins grande.\n",
    "\n",
    "<img src=\"Images\\XavierWine.png\">\n",
    "\n",
    "<img src=\"Images\\ZeroWine.png\">\n",
    "\n",
    "Les apprentissages pour les figures 3 et 4 utilisent le même learning rate, mais on voit que l’initialisation à zéro converge beaucoup plus rapidement tandis que l’initialisation de Xavier s’améliore constamment. L’initialisation à zéro risque donc de converger à un taux plus faible.\n",
    "\n",
    "<img src=\"Images\\XavierAbalone.png\">\n",
    "\n",
    "<img src=\"Images\\ZeroAbalone.png\">\n",
    "\n",
    "Sur le jeu de données Abalone, on observe la même chose que sur le jeu de donnée Wine. C’est-à-dire que l’initialisation à zéro converge trop rapidement donc elle pourrait mal converger.\n",
    "\n",
    "\n",
    "### Évaluation\n",
    "\n",
    "Pour les jeux de données Iris, Wine et Abalone, on utilise respectivement 3, 8 et 6 couches cachées. On utilise un learning rate de 0.01 pour les 3 modèles.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th></th>\n",
    "        <th>Accuracy</th>\n",
    "        <th>Precision</th>\n",
    "        <th>Recall</th>\n",
    "        <th>F1-score</th>\n",
    "        <th>Temps d'entrainement</th>\n",
    "        <th>Temps d'évaluation</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>iris</th>\n",
    "        <td>[100, 58, 58]</td>\n",
    "        <td>[100, 37.5, nan]</td>\n",
    "        <td>[100, 100, 0]</td>\n",
    "        <td>[100, 54.54, 0]</td>\n",
    "        <td>18.79</td>\n",
    "        <td>0.00523</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>wine</th>\n",
    "        <td>71.48</td>\n",
    "        <td>72.25</td>\n",
    "        <td>83.89</td>\n",
    "        <td>77.63</td>\n",
    "        <td>347.356</td>\n",
    "        <td>0.13299</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>abalone</th>\n",
    "        <td>[87, 79.27, 91.79]</td>\n",
    "        <td>[50, 78.62, 97.435]</td>\n",
    "        <td>[2.45, 99.79, 27.14]</td>\n",
    "        <td>[4.678, 87.95, 42.46]</td>\n",
    "        <td>491.70</td>\n",
    "        <td>0.1595</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Matrices de confusion Iris: \n",
    "\n",
    "$$\\begin{bmatrix} 8 & 0\\\\ 0 & 4 \\end{bmatrix}$$\n",
    "$$\\begin{bmatrix} 4 & 5\\\\ 0 & 3 \\end{bmatrix}$$\n",
    "$$\\begin{bmatrix} 7 & 0\\\\ 5 & 0 \\end{bmatrix}$$\n",
    "\n",
    "\n",
    "Matrice de confusion Wine: \n",
    "$$\\begin{bmatrix} 178 & 154\\\\ 77 & 401 \\end{bmatrix}$$\n",
    "\n",
    "\n",
    "Matrices de confusion Abalone : \n",
    "$$\\begin{bmatrix} 1087 & 4\\\\ 159 & 4 \\end{bmatrix}$$\n",
    "$$\\begin{bmatrix} 45 & 258\\\\ 2 & 949 \\end{bmatrix}$$\n",
    "$$\\begin{bmatrix} 1113 & 1\\\\ 102 & 38 \\end{bmatrix}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recherche d'hyperparamètres\n",
    "\n",
    "### Choix du nombre de neurones dans la couche cachée\n",
    "\n",
    "#### Iris\n",
    "\n",
    "La figure ci-dessous montre que, pour le jeu de données Iris, l'erreur est minimale lorsqu'on utilise 2, 4, 5 ou 6 neurones. Nous avons décidé d'en utiliser 4.\n",
    "\n",
    "<img src=\"Images\\nb_neurones_Iris.png\">\n",
    "\n",
    "\n",
    "#### Wine\n",
    "\n",
    "La figure ci-dessous montre que, pour le jeu de données Wine, l'erreur est minimale lorsqu'on utilise 7 neurones. C'est donc le nombre de neurones que nous avons utilisé.\n",
    "\n",
    "<img src=\"Images\\nb_neurones_Wine.png\">\n",
    "\n",
    "\n",
    "#### Abalone\n",
    "\n",
    "La figure ci-dessous est pour le jeu de donnée Abalone. On remarque que plus il y a de neurones, plus l'erreur est petite. Nous utilisons 6 neurones selon ce graphique.\n",
    "\n",
    "<img src=\"Images\\nb_neurones_Abalone.png\">\n",
    "\n",
    "\n",
    "### Choix du nombre de couches cachées\n",
    "\n",
    "#### Iris\n",
    "\n",
    "Selon la figure ci-dessous, on utilise une seule couche cachée pour le jeu de donnée Iris. En effet, plus il y a de couches, plus l'erreur est grande. On utilise donc un réseau ayant une couche cachée et 4 neurones.\n",
    "\n",
    "<img src=\"Images\\nb_couches_Iris.png\">\n",
    "\n",
    "\n",
    "#### Wine\n",
    "\n",
    "Encore une fois, la figure semble montrer que le meilleur réseau utilise une seule couche cachée. On utilise donc un réseau ayant une couche cachée et 7 neurones. \n",
    "\n",
    "<img src=\"Images\\nb_couches_Wine.png\">\n",
    "\n",
    "\n",
    "#### Abalone\n",
    "\n",
    "On observe la même tendance par rapport au fait que plus il y a de couche, plus l'erreur est grande. On utilise donc un modèle avec 2 couches cachées et 6 neurones par couche.\n",
    "\n",
    "<img src=\"Images\\nb_couches_Abalone.png\">\n",
    "\n",
    "#### Phénomène de Vanishing Gradient\n",
    "Le Vanishing Gradient est un phénomène qui se produit lorsqu'il y a beaucoup de couches dans un réseau de neurones. Ce phénomène rend l'apprentissage beaucoup plus lent. En effet, plus il y a de couches, moins la variation dans les premiers poids est grande. C'est le cas car, pour obtenir le gradient d'un poids, il faut passer par chacun des autres noeuds. On a donc une chaîne de multiplication de plusieurs petites valeurs. Donc plus un poids est loin de la dernière couche, moins il changement rapidement.\n",
    "\n",
    "Dans les figures pour les choix de nombres de couches, on a pu observer qu'un plus grand nombre de couches apportait généralement plus d'erreur. C'est peut-être dù au fait que nous avons utiliser le même nombre d'itérations maximum pour tous les nombres de couches. Les modèles avec plus de couches auraient probablement nécessité plus d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement et test\n",
    "\n",
    "Avec les choix de nombres de neurones et de nombres de couches, on obtient les résultats suivant :\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th></th>\n",
    "        <th>Accuracy</th>\n",
    "        <th>Precision</th>\n",
    "        <th>Recall</th>\n",
    "        <th>F1-score</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>iris</th>\n",
    "        <td>58.33</td>\n",
    "        <td>45.83</td>\n",
    "        <td>66.66</td>\n",
    "        <td>51.51</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>wine</th>\n",
    "        <td>81.73</td>\n",
    "        <td>81.28</td>\n",
    "        <td>80.70</td>\n",
    "        <td>80.95</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>abalone</th>\n",
    "        <td>82.70</td>\n",
    "        <td>74.96</td>\n",
    "        <td>64.79</td>\n",
    "        <td>68.72</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Matrices de confusion Iris : \n",
    "$$\\begin{bmatrix} 8 & 0\\\\ 0 & 4 \\end{bmatrix}$$\n",
    "$$\\begin{bmatrix} 4 & 5\\\\ 0 & 3 \\end{bmatrix}$$\n",
    "$$\\begin{bmatrix} 7 & 0\\\\ 5 & 0 \\end{bmatrix}$$\n",
    "\n",
    "\n",
    "Matrice de confusion Wine : \n",
    "$$\\begin{bmatrix} 249 & 83\\\\ 65 & 413 \\end{bmatrix}$$\n",
    "\n",
    "\n",
    "Matrices de confusion Abalone: \n",
    "$$\\begin{bmatrix} 1089 & 25\\\\ 55 & 85 \\end{bmatrix}$$\n",
    "$$\\begin{bmatrix} 151 & 152\\\\ 65 & 886 \\end{bmatrix}$$\n",
    "$$\\begin{bmatrix} 1051 & 40\\\\ 97 & 66 \\end{bmatrix}$$\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparaison entre les algorithmes expérimentés dans le cours\n",
    "\n",
    "<img src=\"Images\\Comparaison.png\" style=\"width:100%;\">\n",
    "\n",
    "L'arbre de décision a les meilleurs résultats pour tous les jeux de données tout en ayant des temps d'entraînement et de prédiction raisonnablement petits. Le KNN performe également très bien dans tous les jeux de données, mais il a un temps de prédiction beaucoup plus long. L'arbre est donc préférable pour nos jeux de données.\n",
    "\n",
    "Pour le jeu de données Iris, le réseau de neurones a très mal performé. C'est probablement parce que ce genre de modèle nécessite beaucoup de données pour bien s'entraîner. Ce modèle est également très long à entraîner et il aurait peut-être performé mieux avec davantage d'entraînement.\n",
    "\n",
    "Contrairement aux réseaux neurones, le classifieur naïf de Bayes semble être meilleur sur les plus petits jeux de données comme Iris. Il performe très mal sur abalone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Ce projet nous a permis d'apprendre comment fonctionne les algorithmes de KNN, de CNB, d'arbres de décisions et de réseaux neurones.\n",
    "\n",
    "Nous avons également appris des techniques qui nous permettent de combattre l'overfitting, comme l'élagage des arbres et le choix du nombre d'itérations dans les réseaux neurones.\n",
    "\n",
    "Nous avons appris à utiliser la validation croisée pour faire la sélection d'hyperparamètres de nos modèles."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
